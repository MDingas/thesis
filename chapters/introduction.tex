\chapter{Introduction}

\section{Context and motivation}

    As society as a whole advances, so does seem to increase the individual's quality of life, which in turn increases the standard to be expected from the society he lives in.
    As such, technology itself must quickly adapt to the needs of the people it serves, whichever they may be - educational, medical, logistical, just to name a few - and consistently create or improve upon solutions that inevitably change the day-to-day living of the many that use or indirectly reap the benefits of such solutions.
    A particular example that is still fresh in this generation is in the relationship between people and computers - where they may have been nonexistent a century ago, reserved for industries fifty years ago and valuable household commodity a few decades ago, it is now common to see a family home with more than a dozen computers, with a variety fitting for the many kinds of problems they can solve.
    The increased number of computers and their expected functionalities has made it so computer networking as a whole has to be improved upon.

    The internet allows computers to connect to one another in a worldwide network that applications can use to further increase their possibilities.
    However, when certain applications go unchecked it becomes very difficult for \glspl{isp} because such applications can create traffic which is either impossible, infeasible, or too costly to manage.
    This issue is further exacerbated when considering the scale of the next decade, where Cisco predicts that by 2022 global internet users will make up 60 percent of the world's population, and global IP traffic will reach 396 exabytes per month \cite{cisco2019}.
    The problem of network management will thus increase in difficulty due to the sheer scale of Internet usage, and traffic engineering solutions are then required to provide certain service standards to applications, e.g., the \gls{diffserv} architecture, and more recently \cite{rev1} and \cite{rev2}.

    Considering a network of computers which are running applications to fit a given use case for the user, such as transferring a file, watching a real-time video, or consuming the content of a given social network, these applications are responsible for creating traffic that must be supported by the underlying network infrastructure, meaning all the hardware and software that is utilized by given companies to provide to end users the ability to communicate with each other.
    These applications can be thought of as citizens of a communications facility that provides the service of accessibility to other citizens, and there is a common incentive in maintaining this facility in such a way that keeps the service up to its standards.
    As such, and like any other community-shared facility, it must be maintained by the owners, and part of it includes creating and enforcing policies that uphold the facility's quality.
    During the runtime of an application, the way it is programmed to operate has impact on the traffic it generates on the network, and thus how resourceful it is with the shared domain it uses.
    The logic of the program dictates how the shared network is used to achieve a given goal, and how it accomplishes it can be more or less preferable by the service providers - for example, application decisions such as which hosts to consume a service from, at what time of the day some traffic is generated, or how much traffic is needed to achieve a use case, have a concrete impact on the shared network structure.
    \gls{p2p} applications are an infamous example of a kind of application that often makes decisions that are not preferable by \glspl{isp}.
    These applications create overlay networks, which are abstract networks constructed on top of the underlying network that supports it, and on which the application's logic runs on, essentially making it infrastructure-agnostic.
    Historically, \gls{p2p} traffic has not been preferable by \glspl{isp} due to its unpredictable and hard to manage nature.
    Indeed, if \gls{p2p} applications simply keep an overlay connection between peers that does not span more than a few hops, whilst ignorant to them being, for example, either direct network links or spanning multiple Autonomous Systems (ASs) in the underlay, the generated traffic is always at risk of being inefficient and too taxing on the supporting infrastructure - for example, by neighboring other peers which reside outside network borders, which are more infrastructurally expensive to reach.
    As global file-sharing traffic currently uses around 7 exabytes per month (including \gls{p2p}-based file-sharing) \cite{cisco2019}, and BitTorrent alone makes up 27\% percent of total upstream volume of traffic \cite{sandvine2019} it's in the best interest of both \glspl{isp} and \gls{p2p} applications a way for the overlay and underlay levels to operate in synergy, i.e., how should the layers combine efforts to guarantee that their needs are met in a sustainable manner.

    Current consumer trends suggest that media consumption will make up a considerable part of global Internet traffic.
    In fact, Cisco predicts that, by 2022, more than 82 percent of all consumer Internet traffic will be dedicated to Internet video streaming and downloads, and \glspl{cdn} will carry 72 percent of all Internet traffic \cite{cisco2019}.
    \glspl{cdn} act by injecting content geographically nearby end users to increase availability and reduce total traffic usage, and are an example of how applications can better leverage the shared domain's resources to achieve their goal.
    The \gls{cdn}'s management layer can optimize its application behaviour in ways that are advantageous to both applications using the \gls{cdn} and the shared network structure, and such ways include what edge server to cache data to, how to efficiently match end users to appropriate edge servers, or how to increase service reachability among other \glspl{cdn}.
    Thus, much like \gls{p2p} networks, content distribution networks could also greatly benefit from cooperative interactions with network providers.
    These optimizations should be made by the parties which have economical interest in guaranteeing good performance of the overall ecosystem, i.e., those acting on the over and underlay, and should seek to, resorting to application and network administration input, understand how to utilize the given network resources to achieve functional requirements in a way that is cheap, effective and sustainable.

    More broadly, most kinds of applications that generate traffic on a network could benefit from input by entities which know how such network is structured and what political and administrative biases exist.
    Of course, a one-sided approach could also exist to optimize resourcefulness of the network structure - applications could use an independent internal logic that utilizes measurements and its, albeit limited, knowledge of network details to better aid their decisions, and likewise \glspl{isp} can attempt to throttle, block, or generally apply traffic engineering.
    In fact, these one-sided approaches are precisely what happens currently, but this work aims to argue for a two-sided cooperative approach.

    In short, the issue that motivates this thesis is the lack of proper cooperation between the overlay and underlay levels in the task of optimizing traffic that originates from decisions that occur at the application level, e.g., peer selection for file retrieval in file-sharing \gls{p2p} applications, software distribution mirror selection, CDN provider server or cache redirections, high traffic load scheduling, etc.
    This problem is not new to the \gls{ietf}, who devised a working group to explore possible IETF standardization on traffic localization after test results concluded that \gls{p2p} applications that select peers based on exclusive network information provided by \glspl{isp} could reduce network infrastructural and administrative costs as well as increase application download rates \cite{seedorf2009}.
    Such working group devised a request-response protocol by the same name, \gls{alto}, where clients could query authoritative and trustworthy servers on information that regards to the underlay structure where the client operates.
    While the tussle between \gls{p2p} applications and \glspl{isp} were the motivation for the \gls{alto} working group to be created, the benefits of a standardized, maintained, and well provided system for network information querying and guidance on traffic-related decisions could help create the vision of \glspl{isp} and applications cooperating for mutual benefit, being thus advantageous for more than \gls{p2p} applications - in essence, it would be a helpful system for any situation where a decision could be optimized with the addition of proper insight on network infrastructure.
    This work then focuses on tackling the theme of application-infrastructure cooperation on the Internet, with particular focus on presenting, implementing and improving the \gls{alto} protocol as a cooperation enabler.

\section{Objectives}

    The main objective of this thesis is to develop a working system that adheres to and expands upon the \gls{alto} working group's devised protocol and architecture.
    The starting point will be a preexisting software project that served as a proof of concept to the strategy of traffic optimization at the application layer, which will now be extended in three ways: firstly, by restructuring and documenting the existing code in order to, through the compliance with the standards of object oriented programming and software development guidelines, present a solution that could be continuously maintained and modified; secondly, by further expanding on the software's functionality, e.g., adding more types of cost metrics, specifying meta-data which give the resources a time-specific applicability, specifying means of synchronizing data among servers, restricting user interaction via access control methods, etc); thirdly, by specifying and implementing a network data supply component to the architecture, as one has not been formally defined by the \gls{alto} working group.
    Whilst expanding upon the working group's devised solution is indeed a goal, it is also important that the developed work complies with the specifications it is based on, so the work done by the \gls{ietf} in regards to documentation and general reasoning of the protocol remains consistent with this implementation, with further additions being reasoned in this work.

    With the intent of completing its main goal, this work's partial objectives were devised as follows:

\begin{itemize}
    \item Literature review in regards to application-level traffic optimization and the cooperation - or lack thereof - between overlay networks and the underlay they operate on.
        More specifically, an understanding of what the problem entails, the consensus on the existing issues, and an overview of currently proposed solutions.
    \item Complete overview of the \gls{alto} working group's current work.
        More specifically, an overview of both their existing RFC documents and currently active internet drafts (at the time of writing).
    \item Familiarization with the existing system to be worked on and definition of both a new system architecture which complies with and extends upon the \gls{alto} solution, as well as the new function modules to be added and how they should operate.
    \item Implementation of the devised solution.
    \item Construction of a realistic network simulation scenario and prototype applications to base the experiments in - this includes a \gls{p2p} and server-client file sharing applications.
    \item Testing of the implemented solution within a simulation scenario, and how it compares with other traditional methods in regards to achieved network infrastructural resourcefulness and client application performance.
\end{itemize}

\section{Contributions}

    This thesis's contributions include a working implementation of the \gls{alto} protocol as specified by the working group of the same name, which includes functionally extensions, as well as the implementation of a devised architecture to fulfill the \gls{alto} working group's proposed idea of layer cooperation, that includes a network status supply, resource access control, and domain synchronization layers.
    Additionally, the accomplished experiments in a simulated environment served as empirical proof of the usefulness of an \gls{alto} system for layer cooperation, as it was able to display what is to be gained by using the proposed approach over traditional ones in regards to application performance and optimal network resourcefulness.

\section{Thesis organization}

    This dissertation will be organized in six chapters, as follows:

\begin{itemize}
    \item \textbf{Introduction}: Provides context to the tussle between applications and Internet providers, as well as an argument for the necessity to fix this issue to reach a sustainable environment for both parties. Coupled to this, the dissertation's main goal is presented.
    \item \textbf{State of the Art}: Displays the existing theory related to popular technologies or overall concepts that could leverage the \gls{alto} protocol for improved functionality and/or performance; secondly, displays existing proposed solutions to traffic optimization at the application level that do so using network information with and without close underlay cooperation; thirdly, overviews the \gls{alto} working group's proposed protocol and architecture.
    \item \textbf{System architecture and developed mechanisms}: Presents the devised system's functional and non-functional requirements, as well as an overview of the planned architecture.
    \item \textbf{Implementation}: Provides reasoning to the decisions that were made in the task of implementing the specified project.
    \item \textbf{Experiments}: Overviews the planned simulation scenarios, how they were materialized, how the related tests were performed, and their results.
    \item \textbf{Conclusion}: Presents a critical analysis of the simulation test results, and how they change the previously proposed hypothesis. Finally, it presents the results of this thesis in regards to what objectives were completed, the general conclusions that were retrieved, and future work.
\end{itemize}{}

